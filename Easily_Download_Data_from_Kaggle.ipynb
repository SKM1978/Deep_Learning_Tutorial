{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Easily Download Data from Kaggle.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONly7zsGUpeLA6yEE2msZj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayushkubb/Deep_Learning_Tutorial/blob/master/Easily_Download_Data_from_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VYyX8-3-_1J"
      },
      "source": [
        "Please follow the steps below to download and use kaggle data within Google Colab:\n",
        "\n",
        "1. Go to your account, Scroll to API section and Click Expire API Token to remove previous tokens\n",
        "\n",
        "2. Click on Create New API Token - It will download kaggle.json file on your machine.\n",
        "\n",
        "3. Go to your Google Colab project file and run the following commands:\n",
        "\n",
        "1) ! pip install -q kaggle\n",
        "\n",
        "2) from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "\n",
        "    Choose the kaggle.json file that you downloaded\n",
        "\n",
        "3) ! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "    Make directory named kaggle and copy kaggle.json file there.\n",
        "\n",
        "4) ! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    Change the permissions of the file.\n",
        "\n",
        "5) ! kaggle datasets list\n",
        "- That's all ! You can check if everything's okay by running this command.\n",
        "Download Data\n",
        "\n",
        "! kaggle competitions download -c 'name-of-competition'\n",
        "\n",
        "Use unzip command to unzip the data:\n",
        "\n",
        "For example,\n",
        "\n",
        "Create a directory named train,\n",
        "\n",
        "! mkdir train\n",
        "\n",
        "unzip train data there,\n",
        "\n",
        "! unzip train.zip -d train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc8HT8tg-4B5"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh9AXu_M_Mel"
      },
      "source": [
        " from google.colab import files "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUtb4Z5d_Pqq"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyq_kJsw_YE9"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eFNUSjT_fvM"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ScIs7g_kJy",
        "outputId": "e1bb01fe-8c76-436c-c26f-41741ff9ee10"
      },
      "source": [
        "! kaggle datasets list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              233KB  2021-08-20 08:51:07          10954  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           6708  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           2532  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   2GB  2021-07-03 18:37:20           2686  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           1664  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00           1155  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            803  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            974  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            845  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            290  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            723  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            296  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54            134  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            175  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26            124  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51            122  \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         146911  \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         142201  \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          25912  \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          20901  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOYupMG1_nCl",
        "outputId": "49af7fa6-837d-431a-b061-6ad7af58feba"
      },
      "source": [
        "!kaggle datasets download -d filippoo/deep-learning-az-ann"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading deep-learning-az-ann.zip to /content\n",
            "\r  0% 0.00/262k [00:00<?, ?B/s]\n",
            "\r100% 262k/262k [00:00<00:00, 39.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPbEUSLz_wT8",
        "outputId": "cf9acecb-d097-4b32-a3c4-dd71f92394f2"
      },
      "source": [
        "! unzip /content/deep-learning-az-ann.zip"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/deep-learning-az-ann.zip\n",
            "  inflating: Churn_Modelling.csv     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ySlV55AXf_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}