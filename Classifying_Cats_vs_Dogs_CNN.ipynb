{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying Cats vs. Dogs - CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jgsLehf1ASG650xmSFmQQ37nI9WkZ4mG",
      "authorship_tag": "ABX9TyMj3VqMHCoTPgjaoVeFWzRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SKM1978/Deep_Learning_Tutorial/blob/master/Classifying_Cats_vs_Dogs_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W_IN5G8IGSl"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt4eoGVoILHq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, MaxPool2D, Conv2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6EzCi2XI0iq"
      },
      "source": [
        "# Uploading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8t3A3C4hM0Y"
      },
      "source": [
        "### Steps in uploading the dataset\n",
        "- Upload in Google Drive\n",
        "- Mount the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-og_n3D5nyLc",
        "outputId": "90c5ca5c-1a15-4591-c2f1-4d51d3c95ea7"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z44wmorEZY5_"
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyb3Ofdtb-1w"
      },
      "source": [
        "# checking if the installation has happened properly\n",
        "\n",
        "import keras"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44hOVVFCcNf8"
      },
      "source": [
        "# Resizing all images\n",
        "\n",
        "IMAGE_SIZE=[224,224]\n",
        "\n",
        "\n",
        "# Path to train and test images\n",
        "\n",
        "train_path='/content/drive/MyDrive/Cats & Dogs - Copy/train'\n",
        "test_path='/content/drive/MyDrive/Cats & Dogs - Copy/test'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIh61Nn9EId7"
      },
      "source": [
        "# Transfer Learning with ResNet-50 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TByE5eeSFZcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf376d76-93fe-439c-b2c9-19e4de345e4f"
      },
      "source": [
        "resnet=tf.keras.applications.ResNet50(input_shape=IMAGE_SIZE+[3], include_top=False, weights='imagenet')\n",
        "\n",
        "# Using resnet model only for feature extraction and not for learning, by freezing all the layers that we don't need\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "# Taking the output of the base layers\n",
        "resnet_output=resnet.output\n",
        "\n",
        "# Adding our own layers\n",
        "\n",
        "## Pool Layer\n",
        "x=GlobalAveragePooling2D()(resnet_output)\n",
        "\n",
        "## Flatten Layer\n",
        "x=Flatten()(x)\n",
        "\n",
        "## Batch Normalization\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "## Fully connected Layer\n",
        "x=Dense(500, activation='relu')(x)\n",
        "\n",
        "## Batch Normalization\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "## Dropout Layer\n",
        "x=Dropout(0.3)(x)\n",
        "\n",
        "## Batch Normalization\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "## Outer Layer\n",
        "x=Dense(2, activation='sigmoid')(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3glLUGbEd7G",
        "outputId": "a6c7a1b7-9341-4f71-8397-01e4d03636db"
      },
      "source": [
        "# Initializing the resnet model\n",
        "\n",
        "rs_model=Model(inputs=resnet.input, outputs=x)\n",
        "\n",
        "rs_model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 2048)        8192        ['flatten[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 500)          1024500     ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 500)         2000        ['dense[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 500)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 500)         2000        ['dropout[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            1002        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,625,406\n",
            "Trainable params: 1,031,598\n",
            "Non-trainable params: 23,593,808\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlPv3wqHIGRw"
      },
      "source": [
        "rs_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLclOQNzJnSW"
      },
      "source": [
        "### Image Generator and Augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEsjcJuCJujC"
      },
      "source": [
        "# Using the ImageDataGenerator to import images from the dataset\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale=1/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, vertical_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1/255.0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8cH_TpiEbgG",
        "outputId": "de9b7706-bcae-4df9-a1b3-70dc712fba1a"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "\n",
        "train_set=train_datagen.flow_from_directory('/content/drive/MyDrive/Cats & Dogs - Copy/train', target_size=(224,224), class_mode='categorical', batch_size=32)\n",
        "test_set=test_datagen.flow_from_directory('/content/drive/MyDrive/Cats & Dogs - Copy/test', target_size=(224,224), class_mode='categorical', batch_size=32)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2002 images belonging to 2 classes.\n",
            "Found 969 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4j4OzQRL8kK"
      },
      "source": [
        "### Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKfeLwMYL9_D",
        "outputId": "25106d78-3125-48ea-c6a7-babf8b98bec2"
      },
      "source": [
        "result=rs_model.fit_generator(train_set, validation_data=test_set, epochs=100, steps_per_epoch=len(train_set), validation_steps=len(test_set))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 39s 617ms/step - loss: 0.6029 - accuracy: 0.6893 - val_loss: 0.5799 - val_accuracy: 0.6791\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 39s 620ms/step - loss: 0.6025 - accuracy: 0.6903 - val_loss: 0.5892 - val_accuracy: 0.6708\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 39s 622ms/step - loss: 0.6162 - accuracy: 0.6723 - val_loss: 0.5774 - val_accuracy: 0.6914\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 39s 619ms/step - loss: 0.5954 - accuracy: 0.6948 - val_loss: 0.5961 - val_accuracy: 0.6739\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 39s 622ms/step - loss: 0.5917 - accuracy: 0.6983 - val_loss: 0.5713 - val_accuracy: 0.6904\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 39s 620ms/step - loss: 0.5976 - accuracy: 0.6888 - val_loss: 0.6092 - val_accuracy: 0.6821\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 39s 622ms/step - loss: 0.5895 - accuracy: 0.6898 - val_loss: 0.6203 - val_accuracy: 0.6636\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 40s 628ms/step - loss: 0.5890 - accuracy: 0.6903 - val_loss: 0.5943 - val_accuracy: 0.6821\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 39s 614ms/step - loss: 0.5854 - accuracy: 0.6933 - val_loss: 0.6248 - val_accuracy: 0.6471\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 39s 621ms/step - loss: 0.5948 - accuracy: 0.6868 - val_loss: 0.5905 - val_accuracy: 0.6760\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 39s 626ms/step - loss: 0.5816 - accuracy: 0.6988 - val_loss: 0.5934 - val_accuracy: 0.6821\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 40s 628ms/step - loss: 0.5727 - accuracy: 0.7093 - val_loss: 0.5883 - val_accuracy: 0.6760\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 39s 625ms/step - loss: 0.5829 - accuracy: 0.6983 - val_loss: 0.5856 - val_accuracy: 0.6925\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 43s 689ms/step - loss: 0.5695 - accuracy: 0.7043 - val_loss: 0.6012 - val_accuracy: 0.6594\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 40s 631ms/step - loss: 0.5681 - accuracy: 0.6868 - val_loss: 0.5792 - val_accuracy: 0.6801\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 40s 633ms/step - loss: 0.5769 - accuracy: 0.6983 - val_loss: 0.6173 - val_accuracy: 0.6667\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 40s 629ms/step - loss: 0.5695 - accuracy: 0.6968 - val_loss: 0.5803 - val_accuracy: 0.6811\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 40s 628ms/step - loss: 0.5707 - accuracy: 0.7083 - val_loss: 0.5845 - val_accuracy: 0.6894\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 40s 627ms/step - loss: 0.5761 - accuracy: 0.7023 - val_loss: 0.5689 - val_accuracy: 0.7007\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 40s 627ms/step - loss: 0.5756 - accuracy: 0.7013 - val_loss: 0.6113 - val_accuracy: 0.6656\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 43s 684ms/step - loss: 0.5660 - accuracy: 0.7043 - val_loss: 0.5864 - val_accuracy: 0.7028\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 40s 633ms/step - loss: 0.5571 - accuracy: 0.7198 - val_loss: 0.5744 - val_accuracy: 0.7049\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 40s 640ms/step - loss: 0.5681 - accuracy: 0.7088 - val_loss: 0.6073 - val_accuracy: 0.6863\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 40s 636ms/step - loss: 0.5663 - accuracy: 0.7108 - val_loss: 0.5904 - val_accuracy: 0.6698\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 40s 631ms/step - loss: 0.5705 - accuracy: 0.6943 - val_loss: 0.6139 - val_accuracy: 0.6873\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 40s 632ms/step - loss: 0.5473 - accuracy: 0.7343 - val_loss: 0.5793 - val_accuracy: 0.6842\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 40s 632ms/step - loss: 0.5586 - accuracy: 0.7118 - val_loss: 0.5803 - val_accuracy: 0.6966\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 40s 629ms/step - loss: 0.5620 - accuracy: 0.7098 - val_loss: 0.5722 - val_accuracy: 0.6739\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 40s 631ms/step - loss: 0.5525 - accuracy: 0.7088 - val_loss: 0.5687 - val_accuracy: 0.7018\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 41s 645ms/step - loss: 0.5501 - accuracy: 0.7198 - val_loss: 0.5941 - val_accuracy: 0.6821\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 40s 634ms/step - loss: 0.5590 - accuracy: 0.7248 - val_loss: 0.5757 - val_accuracy: 0.6760\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 39s 625ms/step - loss: 0.5459 - accuracy: 0.7243 - val_loss: 0.5959 - val_accuracy: 0.6832\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 39s 622ms/step - loss: 0.5459 - accuracy: 0.7313 - val_loss: 0.5818 - val_accuracy: 0.6925\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 39s 618ms/step - loss: 0.5506 - accuracy: 0.7123 - val_loss: 0.5836 - val_accuracy: 0.6883\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 39s 618ms/step - loss: 0.5602 - accuracy: 0.7108 - val_loss: 0.5727 - val_accuracy: 0.6945\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 39s 617ms/step - loss: 0.5513 - accuracy: 0.7118 - val_loss: 0.5866 - val_accuracy: 0.6739\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 39s 619ms/step - loss: 0.5478 - accuracy: 0.7198 - val_loss: 0.6009 - val_accuracy: 0.6625\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 39s 612ms/step - loss: 0.5414 - accuracy: 0.7183 - val_loss: 0.5919 - val_accuracy: 0.6904\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 40s 630ms/step - loss: 0.5673 - accuracy: 0.6988 - val_loss: 0.5766 - val_accuracy: 0.6894\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 39s 620ms/step - loss: 0.5417 - accuracy: 0.7188 - val_loss: 0.5847 - val_accuracy: 0.6780\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 39s 621ms/step - loss: 0.5462 - accuracy: 0.7248 - val_loss: 0.5867 - val_accuracy: 0.6780\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 39s 615ms/step - loss: 0.5478 - accuracy: 0.7323 - val_loss: 0.5597 - val_accuracy: 0.7007\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 39s 619ms/step - loss: 0.5508 - accuracy: 0.7053 - val_loss: 0.6081 - val_accuracy: 0.6832\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 39s 620ms/step - loss: 0.5398 - accuracy: 0.7258 - val_loss: 0.6245 - val_accuracy: 0.6553\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 39s 616ms/step - loss: 0.5416 - accuracy: 0.7163 - val_loss: 0.5688 - val_accuracy: 0.6966\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 39s 613ms/step - loss: 0.5341 - accuracy: 0.7333 - val_loss: 0.5749 - val_accuracy: 0.6914\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 38s 604ms/step - loss: 0.5372 - accuracy: 0.7268 - val_loss: 0.5732 - val_accuracy: 0.6945\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 39s 615ms/step - loss: 0.5533 - accuracy: 0.7178 - val_loss: 0.5901 - val_accuracy: 0.6873\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 38s 596ms/step - loss: 0.5537 - accuracy: 0.7058 - val_loss: 0.5785 - val_accuracy: 0.7038\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 38s 606ms/step - loss: 0.5380 - accuracy: 0.7308 - val_loss: 0.5860 - val_accuracy: 0.6997\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 38s 608ms/step - loss: 0.5382 - accuracy: 0.7293 - val_loss: 0.5751 - val_accuracy: 0.6801\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 38s 609ms/step - loss: 0.5413 - accuracy: 0.7433 - val_loss: 0.5701 - val_accuracy: 0.6966\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 39s 611ms/step - loss: 0.5520 - accuracy: 0.7263 - val_loss: 0.5928 - val_accuracy: 0.6687\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 39s 623ms/step - loss: 0.5371 - accuracy: 0.7293 - val_loss: 0.6552 - val_accuracy: 0.6388\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 39s 612ms/step - loss: 0.5597 - accuracy: 0.7098 - val_loss: 0.5807 - val_accuracy: 0.6997\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 39s 612ms/step - loss: 0.5297 - accuracy: 0.7283 - val_loss: 0.6291 - val_accuracy: 0.6770\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 39s 615ms/step - loss: 0.5302 - accuracy: 0.7333 - val_loss: 0.5848 - val_accuracy: 0.7038\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 39s 617ms/step - loss: 0.5190 - accuracy: 0.7468 - val_loss: 0.5747 - val_accuracy: 0.6904\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 39s 621ms/step - loss: 0.5211 - accuracy: 0.7418 - val_loss: 0.5971 - val_accuracy: 0.6904\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 39s 613ms/step - loss: 0.5456 - accuracy: 0.7193 - val_loss: 0.5732 - val_accuracy: 0.7038\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 39s 619ms/step - loss: 0.5371 - accuracy: 0.7313 - val_loss: 0.5777 - val_accuracy: 0.6883\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 40s 640ms/step - loss: 0.5117 - accuracy: 0.7443 - val_loss: 0.5997 - val_accuracy: 0.6791\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 40s 633ms/step - loss: 0.5431 - accuracy: 0.7183 - val_loss: 0.6114 - val_accuracy: 0.6656\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 39s 618ms/step - loss: 0.5308 - accuracy: 0.7388 - val_loss: 0.5893 - val_accuracy: 0.7079\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 39s 626ms/step - loss: 0.5196 - accuracy: 0.7463 - val_loss: 0.6377 - val_accuracy: 0.6708\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 40s 639ms/step - loss: 0.5331 - accuracy: 0.7198 - val_loss: 0.5732 - val_accuracy: 0.6976\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 40s 635ms/step - loss: 0.5353 - accuracy: 0.7203 - val_loss: 0.7131 - val_accuracy: 0.6625\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 41s 650ms/step - loss: 0.5333 - accuracy: 0.7268 - val_loss: 0.5985 - val_accuracy: 0.6987\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 40s 640ms/step - loss: 0.5229 - accuracy: 0.7348 - val_loss: 0.5837 - val_accuracy: 0.6935\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 39s 618ms/step - loss: 0.5282 - accuracy: 0.7278 - val_loss: 0.5907 - val_accuracy: 0.6873\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 40s 637ms/step - loss: 0.5383 - accuracy: 0.7193 - val_loss: 0.5820 - val_accuracy: 0.6883\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 38s 608ms/step - loss: 0.5262 - accuracy: 0.7443 - val_loss: 0.5932 - val_accuracy: 0.6863\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 38s 607ms/step - loss: 0.5475 - accuracy: 0.7218 - val_loss: 0.5828 - val_accuracy: 0.6966\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 38s 607ms/step - loss: 0.5252 - accuracy: 0.7338 - val_loss: 0.5879 - val_accuracy: 0.6863\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 39s 618ms/step - loss: 0.5319 - accuracy: 0.7278 - val_loss: 0.5727 - val_accuracy: 0.6987\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 39s 619ms/step - loss: 0.5358 - accuracy: 0.7258 - val_loss: 0.5880 - val_accuracy: 0.6894\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 38s 609ms/step - loss: 0.5245 - accuracy: 0.7418 - val_loss: 0.5937 - val_accuracy: 0.6976\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 38s 599ms/step - loss: 0.5411 - accuracy: 0.7213 - val_loss: 0.5621 - val_accuracy: 0.6956\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 38s 606ms/step - loss: 0.5201 - accuracy: 0.7318 - val_loss: 0.5465 - val_accuracy: 0.7007\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 38s 602ms/step - loss: 0.5201 - accuracy: 0.7388 - val_loss: 0.5711 - val_accuracy: 0.6873\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 39s 613ms/step - loss: 0.5175 - accuracy: 0.7393 - val_loss: 0.5791 - val_accuracy: 0.6976\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 39s 614ms/step - loss: 0.5306 - accuracy: 0.7308 - val_loss: 0.5899 - val_accuracy: 0.6945\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 39s 614ms/step - loss: 0.5213 - accuracy: 0.7338 - val_loss: 0.5796 - val_accuracy: 0.6997\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 39s 611ms/step - loss: 0.5124 - accuracy: 0.7468 - val_loss: 0.5728 - val_accuracy: 0.7018\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 39s 619ms/step - loss: 0.5256 - accuracy: 0.7188 - val_loss: 0.5938 - val_accuracy: 0.6997\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 40s 628ms/step - loss: 0.4993 - accuracy: 0.7617 - val_loss: 0.5916 - val_accuracy: 0.6914\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 40s 642ms/step - loss: 0.5245 - accuracy: 0.7353 - val_loss: 0.5717 - val_accuracy: 0.6863\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 40s 631ms/step - loss: 0.5138 - accuracy: 0.7488 - val_loss: 0.5899 - val_accuracy: 0.6956\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 40s 634ms/step - loss: 0.5069 - accuracy: 0.7453 - val_loss: 0.5877 - val_accuracy: 0.6904\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 39s 625ms/step - loss: 0.5129 - accuracy: 0.7498 - val_loss: 0.5736 - val_accuracy: 0.6883\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 39s 625ms/step - loss: 0.5106 - accuracy: 0.7473 - val_loss: 0.5660 - val_accuracy: 0.7018\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 39s 621ms/step - loss: 0.5101 - accuracy: 0.7408 - val_loss: 0.5669 - val_accuracy: 0.7018\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 39s 619ms/step - loss: 0.5190 - accuracy: 0.7423 - val_loss: 0.5959 - val_accuracy: 0.7038\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 39s 625ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5826 - val_accuracy: 0.6894\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 39s 626ms/step - loss: 0.5129 - accuracy: 0.7507 - val_loss: 0.5900 - val_accuracy: 0.6914\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 39s 620ms/step - loss: 0.5098 - accuracy: 0.7428 - val_loss: 0.5752 - val_accuracy: 0.7059\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 39s 618ms/step - loss: 0.5051 - accuracy: 0.7622 - val_loss: 0.5832 - val_accuracy: 0.6925\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 39s 622ms/step - loss: 0.5048 - accuracy: 0.7488 - val_loss: 0.6044 - val_accuracy: 0.6935\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 39s 624ms/step - loss: 0.5353 - accuracy: 0.7338 - val_loss: 0.5731 - val_accuracy: 0.7079\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 40s 628ms/step - loss: 0.4956 - accuracy: 0.7582 - val_loss: 0.5907 - val_accuracy: 0.7049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVLHDvBO5nbW"
      },
      "source": [
        "### Evaluating the ResNet50 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "A9W48lGW5sTE",
        "outputId": "79cfa4e8-6fdc-46b4-c441-27ee2d19a64d"
      },
      "source": [
        "# plot the accuracy\n",
        "plt.plot(result.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(result.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbMKS9yoFiIO"
      },
      "source": [
        "# Transfer Learning with VGG Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtbbtzxOFtfi"
      },
      "source": [
        "vggnet=tf.keras.applications.VGG19(input_shape=IMAGE_SIZE+[3], include_top=False, weights='imagenet')\n",
        "\n",
        "# Using vggnet model only for feature extraction and not for learning, by freezing all the layers that we don't need\n",
        "for layer in vggnet.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "# Taking the output of the base layers\n",
        "vggnet_output=vggnet.output\n",
        "\n",
        "# Adding our own layers\n",
        "\n",
        "## Pool Layer\n",
        "x=GlobalAveragePooling2D()(vggnet_output)\n",
        "\n",
        "## Flatten Layer\n",
        "x=Flatten()(x)\n",
        "\n",
        "## Batch Normalization\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "## Fully connected Layer\n",
        "x=Dense(500, activation='relu')(x)\n",
        "\n",
        "## Batch Normalization\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "## Dropout Layer\n",
        "x=Dropout(0.3)(x)\n",
        "\n",
        "## Batch Normalization\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "## Outer Layer\n",
        "x=Dense(2, activation='sigmoid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNGGDPZ0BDkx",
        "outputId": "ae9ea635-102a-4bd0-ffc5-16c9350ac952"
      },
      "source": [
        "# Initializing the vggnet model\n",
        "\n",
        "vgg_model=Model(inputs=vggnet.input, outputs=x)\n",
        "\n",
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 500)               256500    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 500)              2000      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 500)              2000      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 1002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,287,934\n",
            "Trainable params: 260,526\n",
            "Non-trainable params: 20,027,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b45U6mL7HAM5"
      },
      "source": [
        "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CIyuXaPLVVt"
      },
      "source": [
        "### Image Generator and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIpoUpvcLYR2"
      },
      "source": [
        "# Using the ImageDataGenerator to import images from the dataset\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "training_datagen=ImageDataGenerator(rescale=1/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, vertical_flip=True)\n",
        "testing_datagen=ImageDataGenerator(rescale=1/255.0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaDq9mLjMf66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3918ad1-e831-442a-aa9d-863460e2be14"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "\n",
        "training_set=training_datagen.flow_from_directory('/content/drive/MyDrive/Cats & Dogs - Copy/train', target_size=(224,224), class_mode='categorical', batch_size=32)\n",
        "testing_set=testing_datagen.flow_from_directory('/content/drive/MyDrive/Cats & Dogs - Copy/test', target_size=(224,224), class_mode='categorical', batch_size=32)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2002 images belonging to 2 classes.\n",
            "Found 969 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRmZZonoLz7D"
      },
      "source": [
        "### Fitting the VGG model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JKK8r2TL2GN",
        "outputId": "1e6af7fe-4d1e-40fb-b193-89812895ecdf"
      },
      "source": [
        "vgg_result=vgg_model.fit_generator(training_set, validation_data=testing_set, epochs=50, steps_per_epoch=len(train_set), validation_steps=len(test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 45s 690ms/step - loss: 0.5174 - accuracy: 0.7672 - val_loss: 0.6085 - val_accuracy: 0.6202\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 43s 680ms/step - loss: 0.4005 - accuracy: 0.8367 - val_loss: 0.5167 - val_accuracy: 0.8679\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 42s 673ms/step - loss: 0.3662 - accuracy: 0.8467 - val_loss: 0.4622 - val_accuracy: 0.8328\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 43s 677ms/step - loss: 0.3316 - accuracy: 0.8601 - val_loss: 0.3959 - val_accuracy: 0.8824\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 42s 677ms/step - loss: 0.3375 - accuracy: 0.8526 - val_loss: 0.3416 - val_accuracy: 0.8710\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 42s 673ms/step - loss: 0.2822 - accuracy: 0.8836 - val_loss: 0.2927 - val_accuracy: 0.8854\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 43s 674ms/step - loss: 0.3059 - accuracy: 0.8626 - val_loss: 0.2705 - val_accuracy: 0.8824\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 43s 676ms/step - loss: 0.3038 - accuracy: 0.8696 - val_loss: 0.2568 - val_accuracy: 0.8927\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 45s 717ms/step - loss: 0.2789 - accuracy: 0.8841 - val_loss: 0.2396 - val_accuracy: 0.8989\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 48s 761ms/step - loss: 0.2664 - accuracy: 0.8891 - val_loss: 0.2552 - val_accuracy: 0.8896\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 48s 763ms/step - loss: 0.2516 - accuracy: 0.8966 - val_loss: 0.2673 - val_accuracy: 0.8875\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 44s 703ms/step - loss: 0.2589 - accuracy: 0.8921 - val_loss: 0.2542 - val_accuracy: 0.8865\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 49s 774ms/step - loss: 0.2373 - accuracy: 0.9041 - val_loss: 0.2553 - val_accuracy: 0.8834\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 49s 773ms/step - loss: 0.2375 - accuracy: 0.8976 - val_loss: 0.2617 - val_accuracy: 0.8813\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 49s 772ms/step - loss: 0.2418 - accuracy: 0.9001 - val_loss: 0.2466 - val_accuracy: 0.8947\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 49s 769ms/step - loss: 0.2412 - accuracy: 0.8961 - val_loss: 0.2630 - val_accuracy: 0.8896\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 49s 770ms/step - loss: 0.2394 - accuracy: 0.9031 - val_loss: 0.2528 - val_accuracy: 0.8927\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 49s 773ms/step - loss: 0.2473 - accuracy: 0.8896 - val_loss: 0.2436 - val_accuracy: 0.8937\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 48s 768ms/step - loss: 0.2365 - accuracy: 0.9046 - val_loss: 0.2571 - val_accuracy: 0.8896\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 47s 749ms/step - loss: 0.2185 - accuracy: 0.9141 - val_loss: 0.2583 - val_accuracy: 0.8958\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 43s 684ms/step - loss: 0.2143 - accuracy: 0.9106 - val_loss: 0.2705 - val_accuracy: 0.8968\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 43s 687ms/step - loss: 0.2049 - accuracy: 0.9121 - val_loss: 0.2696 - val_accuracy: 0.8854\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 43s 688ms/step - loss: 0.2139 - accuracy: 0.9101 - val_loss: 0.2744 - val_accuracy: 0.8793\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 43s 683ms/step - loss: 0.2099 - accuracy: 0.9146 - val_loss: 0.2655 - val_accuracy: 0.8824\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 43s 675ms/step - loss: 0.2214 - accuracy: 0.9051 - val_loss: 0.2916 - val_accuracy: 0.8824\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 43s 682ms/step - loss: 0.1856 - accuracy: 0.9311 - val_loss: 0.2902 - val_accuracy: 0.8875\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 43s 679ms/step - loss: 0.1944 - accuracy: 0.9251 - val_loss: 0.2729 - val_accuracy: 0.8875\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 43s 688ms/step - loss: 0.1778 - accuracy: 0.9241 - val_loss: 0.2828 - val_accuracy: 0.8865\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 43s 677ms/step - loss: 0.1815 - accuracy: 0.9246 - val_loss: 0.2701 - val_accuracy: 0.8937\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 43s 683ms/step - loss: 0.1694 - accuracy: 0.9371 - val_loss: 0.2968 - val_accuracy: 0.8803\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 43s 682ms/step - loss: 0.1905 - accuracy: 0.9206 - val_loss: 0.2940 - val_accuracy: 0.8782\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 43s 682ms/step - loss: 0.1867 - accuracy: 0.9226 - val_loss: 0.2965 - val_accuracy: 0.8803\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 43s 684ms/step - loss: 0.1754 - accuracy: 0.9296 - val_loss: 0.2893 - val_accuracy: 0.8906\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 43s 685ms/step - loss: 0.1841 - accuracy: 0.9236 - val_loss: 0.2939 - val_accuracy: 0.8834\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 43s 683ms/step - loss: 0.1608 - accuracy: 0.9346 - val_loss: 0.3078 - val_accuracy: 0.8875\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 43s 681ms/step - loss: 0.1570 - accuracy: 0.9416 - val_loss: 0.2839 - val_accuracy: 0.8906\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 43s 685ms/step - loss: 0.1733 - accuracy: 0.9316 - val_loss: 0.3154 - val_accuracy: 0.8813\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 43s 681ms/step - loss: 0.1660 - accuracy: 0.9381 - val_loss: 0.2865 - val_accuracy: 0.8927\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 43s 677ms/step - loss: 0.1758 - accuracy: 0.9296 - val_loss: 0.3149 - val_accuracy: 0.8875\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 43s 678ms/step - loss: 0.1605 - accuracy: 0.9351 - val_loss: 0.2982 - val_accuracy: 0.8824\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 45s 711ms/step - loss: 0.1611 - accuracy: 0.9356 - val_loss: 0.3082 - val_accuracy: 0.8824\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 48s 769ms/step - loss: 0.1707 - accuracy: 0.9311 - val_loss: 0.2806 - val_accuracy: 0.8865\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 48s 764ms/step - loss: 0.1544 - accuracy: 0.9331 - val_loss: 0.2974 - val_accuracy: 0.8772\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 45s 713ms/step - loss: 0.1428 - accuracy: 0.9441 - val_loss: 0.2853 - val_accuracy: 0.8803\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 49s 770ms/step - loss: 0.1478 - accuracy: 0.9421 - val_loss: 0.2899 - val_accuracy: 0.8875\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 48s 768ms/step - loss: 0.1580 - accuracy: 0.9346 - val_loss: 0.3106 - val_accuracy: 0.8793\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 49s 774ms/step - loss: 0.1516 - accuracy: 0.9426 - val_loss: 0.3168 - val_accuracy: 0.8793\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 49s 771ms/step - loss: 0.1329 - accuracy: 0.9456 - val_loss: 0.3038 - val_accuracy: 0.8813\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 49s 772ms/step - loss: 0.1445 - accuracy: 0.9436 - val_loss: 0.3339 - val_accuracy: 0.8885\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 49s 772ms/step - loss: 0.1604 - accuracy: 0.9301 - val_loss: 0.3126 - val_accuracy: 0.8824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw5JGL1IXhVs"
      },
      "source": [
        "### Evaluating the VGG Net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "EyaJjZAzXkKs",
        "outputId": "0ed0eb74-6e32-4702-994f-9eb21d912d82"
      },
      "source": [
        "# plot the accuracy\n",
        "plt.plot(vgg_result.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(vgg_result.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUAPAKPIl-nX"
      },
      "source": [
        "# Keras Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lx44OKnwSIg"
      },
      "source": [
        "Helps in deciding the following hyper parameters\n",
        "(1) Number of layers\n",
        "(2) Number of neurons in each layer\n",
        "(3) Learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTq4VgoPwiqq",
        "outputId": "c48c8a55-9795-4a19-a818-5a60789da008"
      },
      "source": [
        "!pip install keras-tuner\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras_tuner import RandomSearch\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |                            | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |                         | 20 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |                      | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |                  | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |               | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |            | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |        | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |     | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |  | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     || 98 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.41.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KwEZbA1xAmW"
      },
      "source": [
        "# Building the function to find the best hyper parameters\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    for i in range(hp.Int('num_layers', 2, 30)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=32,\n",
        "                                            max_value=512,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "    model.add(layers.Dense(2, activation='sigmoid'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTY728kN05DS"
      },
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='project',\n",
        "    project_name='Cats vs. Dogs classification')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "HMDGgJahmD8e",
        "outputId": "07ea4b49-ddba-43ee-d74f-ba12cea7c3d8"
      },
      "source": [
        "tuner.search(training_set, epochs=5, validation_data=testing_set)\n",
        "best_model = tuner.get_best_models()[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "num_layers        |14                |?                 \n",
            "units_0           |160               |?                 \n",
            "units_1           |128               |?                 \n",
            "learning_rate     |0.01              |?                 \n",
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4e48ba4eb45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# objective left unspecified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, None, None, 2) vs (None, None)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bdMCGSUl9of"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}